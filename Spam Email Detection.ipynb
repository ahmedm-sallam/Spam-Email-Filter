{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam Email Detection: Comparative Analysis of Machine Learning Models and Feature Extraction Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer,WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import gensim\n",
    "from gensim.models import Word2Vec, Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"data/Spam_Email_Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of the data: \n",
      "                                                 text  target\n",
      "0  From ilug-admin@linux.ie Mon Jul 29 11:28:02 2...       0\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5796 entries, 0 to 5795\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    5796 non-null   object\n",
      " 1   target  5796 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 90.7+ KB\n",
      "None\n",
      "Missing values in each column: \n",
      " text      0\n",
      "target    0\n",
      "dtype: int64\n",
      "Distribution of target classes: \n",
      " target\n",
      "0    3900\n",
      "1    1896\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample of the data: \\n\", df.head(1))\n",
    "print(df.info())\n",
    "print(\"Missing values in each column: \\n\", df.isna().sum())\n",
    "print(\"Distribution of target classes: \\n\", df['target'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "Here, we clean our text data using various NLP techniques like stemming and removing stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessing(text):\n",
    "    text = re.sub(r'\\S+@\\S+', '', text)  # Remove email addresses\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove non-alphabetic characters\n",
    "    text = re.sub(r'<.*?>', '', text)  # Remove HTML tags\n",
    "    tokens = word_tokenize(text.lower())  # Tokenize and convert to lowercase\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]  # Remove stopwords\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(text_preprocessing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction\n",
    "## Non-Neural Network-Based Embeddings\n",
    "We split the data into training and testing sets and apply feature extraction techniques that  based on Non-Neural Network such as Count Vectorizer and TF-IDF Vectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['target'], test_size=0.4, random_state=135)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_vectorizer = CountVectorizer()\n",
    "X_train_counts = bow_vectorizer.fit_transform(X_train)\n",
    "X_test_counts = bow_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network-Based Embeddings\n",
    "Prepares the data for embeddings using Word2Vec, Doc2Vec, and BERT models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize data for Word2Vec and Doc2Vec\n",
    "sentences = [row.split() for row in df['text']]\n",
    "word2vec_model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4, sg=1)  # sg=1 for skip-gram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word2vec_embedding(text):\n",
    "    words = text.split()\n",
    "    embedding = np.mean([word2vec_model.wv[word] for word in words if word in word2vec_model.wv], axis=0)\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_w2v = np.array([get_word2vec_embedding(text) for text in X_train])\n",
    "X_test_w2v = np.array([get_word2vec_embedding(text) for text in X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Doc2Vec embeddings\n",
    "tagged_data = [TaggedDocument(words=_d.split(), tags=[str(i)]) for i, _d in enumerate(df['text'])]\n",
    "doc2vec_model = Doc2Vec(tagged_data, vector_size=100, window=5, min_count=1, workers=4, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_d2v = np.array([doc2vec_model.infer_vector(text.split()) for text in X_train])\n",
    "X_test_d2v = np.array([doc2vec_model.infer_vector(text.split()) for text in X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT embeddings setup\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bert_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state[:,0,:].detach().numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_bert = np.array([get_bert_embedding(text) for text in X_train])\n",
    "X_test_bert = np.array([get_bert_embedding(text) for text in X_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Evaluation\n",
    "This section trains Logistic Regression and Random Forest models and save them\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(classifier, X_train, y_train):\n",
    "    model = classifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, zero_division=1)\n",
    "    recall = recall_score(y_test, y_pred, zero_division=1)\n",
    "    f1 = f1_score(y_test, y_pred, zero_division=1)\n",
    "    return {\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1 Score\": f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, filename):\n",
    "    # Create directory if it doesn't exist\n",
    "    if not os.path.exists('saved_models'):\n",
    "        os.makedirs('saved_models')\n",
    "    \n",
    "    # Define the path to save the model\n",
    "    path = os.path.join('saved_models', filename)\n",
    "    \n",
    "    # Save the model\n",
    "    with open(path, 'wb') as file:\n",
    "        pickle.dump(model, file)\n",
    "    print(f\"Model saved as {path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(feature_type, X_train, y_train, X_test, y_test):\n",
    "    results = []\n",
    "\n",
    "    # Logistic Regression\n",
    "    lr_model = train_model(LogisticRegression, X_train, y_train)\n",
    "    lr_results = evaluate_model(lr_model, X_test, y_test)\n",
    "    lr_results['Model'] = f'Logistic Regression ({feature_type})'\n",
    "    results.append(lr_results)\n",
    "    save_model(lr_model, f'LR_{feature_type}.pkl')\n",
    "\n",
    "    # Random Forest\n",
    "    rf_model = train_model(RandomForestClassifier, X_train, y_train)\n",
    "    rf_results = evaluate_model(rf_model, X_test, y_test)\n",
    "    rf_results['Model'] = f'Random Forest ({feature_type})'\n",
    "    results.append(rf_results)\n",
    "    save_model(rf_model, f'RF_{feature_type}.pkl')\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as LR_count_vectorizer.pkl\n",
      "Model saved as RF_count_vectorizer.pkl\n",
      "Model saved as LR_tfidf_vectorizer.pkl\n",
      "Model saved as RF_tfidf_vectorizer.pkl\n",
      "Model saved as LR_word2vec.pkl\n",
      "Model saved as RF_word2vec.pkl\n",
      "Model saved as LR_doc2vec.pkl\n",
      "Model saved as RF_doc2vec.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as LR_bert.pkl\n",
      "Model saved as RF_bert.pkl\n",
      "   Accuracy  Precision    Recall  F1 Score  \\\n",
      "0  0.993100   0.990371  0.987654  0.989011   \n",
      "1  0.985770   0.984680  0.969822  0.977194   \n",
      "2  0.976283   0.992690  0.931413  0.961076   \n",
      "3  0.986201   0.990155  0.965706  0.977778   \n",
      "4  0.986201   0.992928  0.962963  0.977716   \n",
      "5  0.983614   0.985935  0.961591  0.973611   \n",
      "6  0.965502   0.958982  0.930041  0.944290   \n",
      "7  0.938767   0.956454  0.843621  0.896501   \n",
      "8  0.987063   0.983402  0.975309  0.979339   \n",
      "9  0.969383   0.991045  0.910837  0.949249   \n",
      "\n",
      "                                    Model  \n",
      "0  Logistic Regression (count_vectorizer)  \n",
      "1        Random Forest (count_vectorizer)  \n",
      "2  Logistic Regression (tfidf_vectorizer)  \n",
      "3        Random Forest (tfidf_vectorizer)  \n",
      "4          Logistic Regression (word2vec)  \n",
      "5                Random Forest (word2vec)  \n",
      "6           Logistic Regression (doc2vec)  \n",
      "7                 Random Forest (doc2vec)  \n",
      "8              Logistic Regression (bert)  \n",
      "9                    Random Forest (bert)  \n"
     ]
    }
   ],
   "source": [
    "# Assuming X_train_counts, X_test_counts, X_train_tfidf, X_test_tfidf, etc. are already defined\n",
    "results_counts = train_and_evaluate('count_vectorizer', X_train_counts, y_train, X_test_counts, y_test)\n",
    "results_tfidf = train_and_evaluate('tfidf_vectorizer', X_train_tfidf, y_train, X_test_tfidf, y_test)\n",
    "results_w2v = train_and_evaluate('word2vec', X_train_w2v, y_train, X_test_w2v, y_test)\n",
    "results_d2v = train_and_evaluate('doc2vec', X_train_d2v, y_train, X_test_d2v, y_test)\n",
    "results_bert = train_and_evaluate('bert', X_train_bert, y_train, X_test_bert, y_test)\n",
    "\n",
    "# Combine and display all results\n",
    "all_results = results_counts + results_tfidf + results_w2v + results_d2v + results_bert\n",
    "results_df = pd.DataFrame(all_results)\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation Results\n",
    "\n",
    "The table below summarizes the performance metrics of the different models trained using various feature extraction techniques. Each row corresponds to a specific model and its associated performance metrics such as accuracy, precision, recall, and F1 score.\n",
    "\n",
    "| Model                                 | Accuracy | Precision | Recall  | F1 Score |\n",
    "|---------------------------------------|----------|-----------|---------|----------|\n",
    "| Logistic Regression (count_vectorizer)| 0.9931   | 0.9904    | 0.9877  | 0.9890   |\n",
    "| Random Forest (count_vectorizer)      | 0.9858   | 0.9847    | 0.9698  | 0.9772   |\n",
    "| Logistic Regression (tfidf_vectorizer)| 0.9763   | 0.9927    | 0.9314  | 0.9611   |\n",
    "| Random Forest (tfidf_vectorizer)      | 0.9862   | 0.9902    | 0.9657  | 0.9778   |\n",
    "| Logistic Regression (word2vec)        | 0.9862   | 0.9929    | 0.9630  | 0.9777   |\n",
    "| Random Forest (word2vec)              | 0.9836   | 0.9859    | 0.9616  | 0.9736   |\n",
    "| Logistic Regression (doc2vec)         | 0.9655   | 0.9590    | 0.9300  | 0.9443   |\n",
    "| Random Forest (doc2vec)               | 0.9388   | 0.9565    | 0.8436  | 0.8965   |\n",
    "| Logistic Regression (bert)            | 0.9871   | 0.9834    | 0.9753  | 0.9793   |\n",
    "| Random Forest (bert)                  | 0.9694   | 0.9910    | 0.9108  | 0.9492   |\n",
    "\n",
    "## Observations and Analysis\n",
    "\n",
    "- **Count Vectorizer Models**: Both Logistic Regression and Random Forest models trained with count vectorizer features show high accuracy, precision, and F1 scores. This suggests good generalization on the test data.\n",
    "- **TF-IDF Vectorizer Models**: TF-IDF models also perform well, especially in terms of precision, indicating fewer false positives.\n",
    "- **Word2Vec Models**: These models have demonstrated strong performance, particularly the Logistic Regression model, which exhibits high scores across all metrics.\n",
    "- **Doc2Vec Models**: While still performing respectably, the Doc2Vec models show a slight dip in metrics compared to other models, particularly in recall and F1 score.\n",
    "- **BERT Models**: The BERT-based models achieve excellent accuracy and precision, with the Logistic Regression variant showing slightly better recall and F1 scores compared to the Random Forest variant.\n",
    "\n",
    "These results will guide further refinement of models and choice of feature extraction techniques for the spam email classification task.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
