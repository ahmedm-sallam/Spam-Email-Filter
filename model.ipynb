{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "df=pd.read_csv(\"data/Spam_Email_Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of the data : \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From ilug-admin@linux.ie Mon Jul 29 11:28:02 2...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  From ilug-admin@linux.ie Mon Jul 29 11:28:02 2...       0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Sample of the data : \\n\")\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5796 entries, 0 to 5795\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    5796 non-null   object\n",
      " 1   target  5796 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 90.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text      0\n",
      "target    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target\n",
      "0    3900\n",
      "1    1896\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['target'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5796"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = re.sub(r'\\S+@\\S+', '', text)  # Remove email addresses\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove non-alphabetic characters\n",
    "    text= re.sub(r'<.*?>','',text) #Remove HTML tag\n",
    "    tokens = word_tokenize(text.lower())  # Convert to lowercase and tokenize\n",
    "    text = ' '.join(text.split()) # Split text by whitespaces and join back with single space\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "    # Stemming\n",
    "    stemmer = PorterStemmer()\n",
    "    stemmed_tokens = [stemmer.stem(token) for token in filtered_tokens]\n",
    "    \n",
    "    # Lemmatization\n",
    "    #lemmatizer = WordNetLemmatizer()\n",
    "    #lemmatized_tokens = [lemmatizer.lemmatize(token) for token in stemmed_tokens]\n",
    "    return ' '.join(stemmed_tokens)  # Join tokens back into a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['target'], test_size=0.4, random_state=135)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_vectorizer = CountVectorizer(ngram_range=(3, 3))\n",
    "tfidf_vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_counts = bow_vectorizer.fit_transform(X_train)\n",
    "X_test_counts = bow_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Logistic Regression (CountVectorizer)': LogisticRegression(C=0.5, random_state=50),\n",
    "    'Random Forest (CountVectorizer)': RandomForestClassifier(n_estimators=100, max_depth=10, min_samples_split=10, random_state=50),\n",
    "    'Logistic Regression (TfidfVectorizer)': LogisticRegression(C=0.5, random_state=50),\n",
    "    'Random Forest (TfidfVectorizer)': RandomForestClassifier(n_estimators=100, max_depth=10, min_samples_split=10, random_state=50)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=[]\n",
    "for model_name, model in models.items():\n",
    "    if 'CountVectorizer' in model_name:\n",
    "        X_train_features = X_train_counts\n",
    "        X_test_features = X_test_counts\n",
    "    elif 'TfidfVectorizer' in model_name:\n",
    "        X_train_features = X_train_tfidf\n",
    "        X_test_features = X_test_tfidf\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train_features, y_train)\n",
    "    \n",
    "    # Make predictions on the training data\n",
    "    y_train_pred = model.predict(X_train_features)\n",
    "    \n",
    "    # Make predictions on the test data\n",
    "    y_pred = model.predict(X_test_features)\n",
    "    \n",
    "    # Calculate evaluation metrics for both train and test\n",
    "    accuracy_train = accuracy_score(y_train, y_train_pred)\n",
    "    accuracy_test = accuracy_score(y_test, y_pred)\n",
    "    precision_train = precision_score(y_train, y_train_pred)\n",
    "    precision_test = precision_score(y_test, y_pred)\n",
    "    recall_train = recall_score(y_train, y_train_pred)\n",
    "    recall_test = recall_score(y_test, y_pred)\n",
    "    f1_train = f1_score(y_train, y_train_pred)\n",
    "    f1_test = f1_score(y_test, y_pred)\n",
    "    \n",
    "    # Store the evaluation results\n",
    "    results.append({\n",
    "        'Model': model_name,\n",
    "        'Test Accuracy': accuracy_test,\n",
    "        'Test Precision': precision_test,\n",
    "        'Test Recall': recall_test,\n",
    "        'Test F1-score': f1_test\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Evaluation Results: \n",
      "\n",
      "                                   Model  Test Accuracy  Test Precision  \\\n",
      "0  Logistic Regression (CountVectorizer)       0.985339        0.984658   \n",
      "1        Random Forest (CountVectorizer)       0.851660        0.994859   \n",
      "2  Logistic Regression (TfidfVectorizer)       0.968521        0.992492   \n",
      "3        Random Forest (TfidfVectorizer)       0.948254        0.988764   \n",
      "\n",
      "   Test Recall  Test F1-score  \n",
      "0     0.968450       0.976487  \n",
      "1     0.530864       0.692308  \n",
      "2     0.906722       0.947670  \n",
      "3     0.844993       0.911243  \n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nModel Evaluation Results: \\n\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec,Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [row.split() for row in X_train]\n",
    "word2vec_model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4, sg=1)  # sg=1 for skip-gram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word2vec_embedding(text):\n",
    "    words = text.split()\n",
    "    embedding = np.mean([word2vec_model.wv[word] for word in words if word in word2vec_model.wv], axis=0)\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_w2v = np.array([get_word2vec_embedding(text) for text in X_train])\n",
    "X_test_w2v = np.array([get_word2vec_embedding(text) for text in X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_data = [TaggedDocument(words=_d.split(), tags=[str(i)]) for i, _d in enumerate(X_train)]\n",
    "doc2vec_model = Doc2Vec(tagged_data, vector_size=100, window=5, min_count=1, workers=4, epochs=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\anaconda\\Lib\\site-packages\\transformers\\utils\\generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dbbdda9b9984ea8b1207f3ee6620b76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\anaconda\\Lib\\site-packages\\huggingface_hub\\file_download.py:137: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Ahmed M.Sallam\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d1b8cb5f16f444fba16ba34b036e576",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7450241deefb495a9174b98376f59471",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6265be22f90435cae5ed8d45da3204f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_d2v = np.array([doc2vec_model.infer_vector(text.split()) for text in X_train])\n",
    "X_test_d2v = np.array([doc2vec_model.infer_vector(text.split()) for text in X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bert_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state[:,0,:].detach().numpy().flatten() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_bert = np.array([get_bert_embedding(text) for text in X_train])\n",
    "X_test_bert = np.array([get_bert_embedding(text) for text in X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Logistic Regression (Word2Vec)': LogisticRegression(C=0.5, random_state=50),\n",
    "    'Random Forest (Word2Vec)': RandomForestClassifier(n_estimators=100, max_depth=10, min_samples_split=10, random_state=50),\n",
    "    'Logistic Regression (Doc2Vec)': LogisticRegression(C=0.5, random_state=50),\n",
    "    'Random Forest (Doc2Vec)': RandomForestClassifier(n_estimators=100, max_depth=10, min_samples_split=10, random_state=50),\n",
    "    'Logistic Regression (BERT)': LogisticRegression(C=0.5, random_state=50),\n",
    "    'Random Forest (BERT)': RandomForestClassifier(n_estimators=100, max_depth=10, min_samples_split=10, random_state=50)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "results=[]\n",
    "for model_name, model in models.items():\n",
    "    if 'Word2Vec' in model_name:\n",
    "        X_train_features = X_train_w2v\n",
    "        X_test_features = X_test_w2v\n",
    "    elif 'Doc2Vec' in model_name:\n",
    "        X_train_features = X_train_d2v\n",
    "        X_test_features = X_test_d2v\n",
    "    elif 'BERT' in model_name:\n",
    "        X_train_features = X_train_bert\n",
    "        X_test_features = X_test_bert\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train_features, y_train)\n",
    "    \n",
    "    # Make predictions on the training data\n",
    "    y_train_pred = model.predict(X_train_features)\n",
    "    \n",
    "    # Make predictions on the test data\n",
    "    y_pred = model.predict(X_test_features)\n",
    "    \n",
    "    # Calculate evaluation metrics for both train and test\n",
    "    accuracy_train = accuracy_score(y_train, y_train_pred)\n",
    "    accuracy_test = accuracy_score(y_test, y_pred)\n",
    "    precision_train = precision_score(y_train, y_train_pred)\n",
    "    precision_test = precision_score(y_test, y_pred)\n",
    "    recall_train = recall_score(y_train, y_train_pred)\n",
    "    recall_test = recall_score(y_test, y_pred)\n",
    "    f1_train = f1_score(y_train, y_train_pred)\n",
    "    f1_test = f1_score(y_test, y_pred)\n",
    "    \n",
    "    # Store the evaluation results\n",
    "    results.append({\n",
    "        'Model': model_name,\n",
    "        'Test Accuracy': accuracy_test,\n",
    "        'Test Precision': precision_test,\n",
    "        'Test Recall': recall_test,\n",
    "        'Test F1-score': f1_test\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Evaluation Results: \n",
      "\n",
      "                            Model  Test Accuracy  Test Precision  Test Recall  \\\n",
      "0  Logistic Regression (Word2Vec)       0.977145        0.992711     0.934156   \n",
      "1        Random Forest (Word2Vec)       0.981026        0.987198     0.951989   \n",
      "2   Logistic Regression (Doc2Vec)       0.942216        0.977528     0.835391   \n",
      "3         Random Forest (Doc2Vec)       0.912893        0.987061     0.732510   \n",
      "4      Logistic Regression (BERT)       0.982751        0.980474     0.964335   \n",
      "5            Random Forest (BERT)       0.960759        0.978979     0.894376   \n",
      "\n",
      "   Test F1-score  \n",
      "0       0.962544  \n",
      "1       0.969274  \n",
      "2       0.900888  \n",
      "3       0.840945  \n",
      "4       0.972337  \n",
      "5       0.934767  \n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nModel Evaluation Results: \\n\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
